# @package _global_

defaults:
  - model: tacotron2_rf2

verbose: 100
seed: 773

# 1) none 2) tqdm
tqdm: tqdm

cudnn:
  benchmark: true
  deterministic: false

# Multi-gpu
data_parallel: false

###########################################################
#                DATA SETTING                             #
###########################################################
data:
  # training set
  train:
    utt_list: data/train.list
    in_dir: dummy # 必要な場合、引数で指定する
    out_dir: dummy # 必要な場合、引数で指定する

  # development set
  dev:
    utt_list: data/dev.list
    in_dir:
    out_dir:
  # dev:
  #   # utt_list: data/wagahai_data/wagahai_all_spk.list
  #   utt_list: data/wagahai_data/wagahai_from_070_spk.list
  #   in_dir: dump/wagahai_all_spk/feats/001-100-model
  #   out_dir: dump/wagahai_all_spk/feats/001-100-model # エラー回避のため
  #   inf_dir: outputs/wagahai_all_spk/001-100-model

  # data loader
  num_workers: 4
  # batch_size: 128
  batch_size: 256

###########################################################
#                TRAIN SETTING                            #
###########################################################
train:
  # out_dir: exp
  # log_dir: tensorboard/exp

  # out_dir: exp_wo_spkpre
  # log_dir: tensorboard/exp_wo_spkpre

  # out_dir: exp_spkrec
  # log_dir: tensorboard/exp_spkrec

  # out_dir: exp_002_008_w_audio
  # log_dir: tensorboard/exp_002_008_w_audio

  # out_dir: exp_002_008_w_audio_rate
  # log_dir: tensorboard/exp_002_008_w_audio_rate
  # out_dir: exp_002_008_w_audio_rate_vo07
  # log_dir: tensorboard/exp_002_008_w_audio_rate_vo07
  # out_dir: exp_002_008_w_audio_rate_vo95
  # log_dir: tensorboard/exp_002_008_w_audio_rate_vo95
  # out_dir: exp_002_008_w_audio_rate_vo90
  # log_dir: tensorboard/exp_002_008_w_audio_rate_vo90

  # out_dir: exp_xvec/${now:%Y-%m-%d_%H:%M:%S}
  # log_dir: tensorboard/exp/${now:%Y-%m-%d_%H:%M:%S}
  # out_dir: exp_xvec/${now:%Y-%m-%d_%H:%M:%S}_wo_xvec
  # log_dir: tensorboard/exp/${now:%Y-%m-%d_%H:%M:%S}_wo_xvec

  # out_dir: exp_xvec/${now:%Y-%m-%d_%H:%M:%S}_d64
  # log_dir: tensorboard/exp/${now:%Y-%m-%d_%H:%M:%S}_d64
  # out_dir: exp_xvec/${now:%Y-%m-%d_%H:%M:%S}_d64_norm
  # log_dir: tensorboard/exp/${now:%Y-%m-%d_%H:%M:%S}_d64_norm

  # out_dir: exp_xvec/${now:%Y-%m-%d_%H:%M:%S}_d64_baseline
  # log_dir: tensorboard/exp/${now:%Y-%m-%d_%H:%M:%S}_d64_baseline

  out_dir: exp_xvec/${now:%Y-%m-%d_%H:%M:%S}_baseline_wo_norm
  log_dir: tensorboard/exp/${now:%Y-%m-%d_%H:%M:%S}_baseline_wo_norm

  # steps can either be specified by steps or epochs
  # max_train_steps: 10000
  max_train_steps: 100000
  nepochs: 100 # validationのloss的にこれぐらいでも十分
  # nepochs: 200
  # nepochs: -1
  # checkpoint_epoch_interval: 50
  checkpoint_epoch_interval: 1 # 毎エポック残す。Discの消費が激しいので、必ずnepochsを指定する
  eval_epoch_interval: 10

  optim:
    optimizer:
      name: Adam
      params:
        lr: 0.0005
        betas: [0.9, 0.999]
        eps: 1e-6
        weight_decay: 0
    lr_scheduler:
      name: StepLR
      params:
        step_size: 100000
        gamma: 0.5

  pretrained:
    checkpoint: "/home/hosoi/git/ttslearn/extra_recipes/jvs/multispk_tacotron2_pwg/exp/jvs001-100_sr24000/tacotron2_rf2_jvs001_jvs100/best_loss.pth"
    # checkpoint: "/home/hosoi/git/ttslearn/extra_recipes/jvs/multispk_tacotron2_pwg/exp_xvec/2023-11-13_12:21:52_wo_xvec/latest.pth"

